---
title: "Scaling AI Services on AWS: From 0 to 300+ Users"
date: "2025-01-15"
description: "Infrastructure decisions, cost optimization strategies, and lessons learned deploying AI services on AWS from prototype to production scale."
tags: ["AWS", "Infrastructure", "MLOps", "Scaling"]
---

When we started our AI supply chain startup, I had to make critical infrastructure decisions with limited resources. Here's how we went from a local prototype to serving 300+ users on AWS.

## Initial Requirements

- **Fast iteration**: Deploy multiple times per day
- **Cost-conscious**: Startup budget, unpredictable usage
- **Scalable**: Handle 10x growth without major rewrites
- **Secure**: Processing sensitive business documents
- **Observable**: Debug production issues quickly

## Architecture Evolution

### Phase 1: Prototype (Month 1)

**Setup**: Everything on a single EC2 instance

```
┌─────────────────────────────┐
│     EC2 t3.medium           │
│  ┌──────────┐  ┌─────────┐  │
│  │ FastAPI  │  │ SQLite  │  │
│  └──────────┘  └─────────┘  │
└─────────────────────────────┘
```

**Cost**: ~$30/month

**Learning**: Good for validating product-market fit, but not scalable.

### Phase 2: Serverless-First (Months 2-3)

**Setup**: Lambda + API Gateway + DynamoDB

```
┌──────────────┐
│ API Gateway  │
└──────┬───────┘
       │
┌──────▼────────┐      ┌────────────┐
│    Lambda     │──────│ DynamoDB   │
└──────┬────────┘      └────────────┘
       │
┌──────▼────────┐
│   Pinecone    │
│  (Vector DB)  │
└───────────────┘
```

**Cost**: ~$150/month (50 users)

**Pros**:
- No server management
- Auto-scaling
- Pay per use

**Cons**:
- Lambda cold starts (2-5s delay)
- 15-minute timeout limits
- Difficult to debug

**Key learning**: Serverless is great for bursty workloads, but not for long-running LLM workflows.

### Phase 3: Hybrid Architecture (Month 4 - Present)

**Current setup**: Mix of Lambda (fast) + ECS (long-running)

```
                  ┌──────────────┐
                  │ CloudFront   │
                  └──────┬───────┘
                         │
                  ┌──────▼───────┐
                  │ API Gateway  │
                  └──┬────────┬──┘
                     │        │
        ┌────────────▼──┐  ┌──▼─────────────┐
        │  Lambda       │  │  ECS Fargate   │
        │  (Quick APIs) │  │  (LLM Agents)  │
        └───────────────┘  └────────────────┘
                │                  │
        ┌───────▼──────────────────▼────┐
        │        DynamoDB / RDS          │
        └────────────────────────────────┘
```

**Cost**: ~$400/month (300 users)

## Key Decisions & Rationale

### 1. Lambda vs. ECS: When to Use Each

**Lambda for**:
- Simple CRUD operations
- Quick API endpoints (<30s)
- Webhooks and event processing

**ECS Fargate for**:
- LLM agent workflows (>30s)
- Background jobs
- GPU workloads (training/inference)

**Cost comparison** (for LLM inference):
- Lambda: $0.20 per 1000 requests (avg 10s runtime)
- ECS: $0.04 per 1000 requests (with auto-scaling)

For our LLM-heavy workload, ECS was 5x cheaper.

### 2. DynamoDB vs. RDS

Started with DynamoDB for:
- Serverless (no management)
- Auto-scaling
- Good for key-value lookups

**Problem**: Complex queries became expensive and slow.

**Solution**: Migrated to RDS Postgres for:
- Relational queries (JOINs!)
- Better tooling (pgAdmin, SQL)
- Predictable costs

**Current approach**:
- DynamoDB for session state, caching
- RDS for core business data

### 3. Infrastructure as Code: AWS CDK

Using **AWS CDK** (TypeScript) instead of CloudFormation or Terraform.

**Why CDK?**

```typescript
// Define entire stack in ~50 lines of type-safe code
const api = new ApiGateway(this, 'API', {
  restApiName: 'ai-supply-chain-api',
});

const lambdaFunction = new Lambda(this, 'ProcessorLambda', {
  runtime: Runtime.PYTHON_3_11,
  handler: 'main.handler',
  code: Code.fromAsset('lambda'),
  timeout: Duration.seconds(30),
  environment: {
    VECTOR_DB_URL: vectorDb.url,
  },
});

api.root.addMethod('POST', new LambdaIntegration(lambdaFunction));
```

**Benefits**:
- Type safety (catch errors before deploy)
- Reusable constructs
- Native AWS support
- Easy to refactor

**Deployment**: `cdk deploy` → full infrastructure in 5 minutes

## Cost Optimization Strategies

### 1. Right-Sizing Instances

**Before**: ECS tasks with 2 vCPU, 4GB RAM
**After**: Profiled actual usage → 0.5 vCPU, 1GB RAM sufficient

**Savings**: 70% reduction in ECS costs

### 2. Spot Instances for Training

When fine-tuning models:
- Use EC2 Spot instances (70% cheaper)
- Auto-checkpoint every 10 minutes
- Resume from checkpoint if interrupted

### 3. Intelligent Caching

```python
# Cache frequently accessed embeddings
@cache(ttl=3600)  # 1 hour
def get_embeddings(doc_id: str):
    return vector_db.query(doc_id)
```

Reduced vector DB queries by 40%.

### 4. Reserved Instances for Base Load

- Reserved Capacity for RDS (30% savings)
- Savings Plans for predictable ECS workload (20% savings)

**Current monthly costs**:
- Compute (ECS + Lambda): ~$200
- Database (RDS + DynamoDB): ~$80
- Vector DB (Pinecone): ~$70
- Other (CloudFront, S3, etc.): ~$50

**Total**: ~$400/month for 300 users = ~$1.33/user/month

## Security & Compliance

### 1. VPC Architecture

```
┌─────────────────── VPC ───────────────────┐
│  ┌──── Public Subnet ────┐                │
│  │  - API Gateway        │                │
│  │  - Load Balancer      │                │
│  └───────────────────────┘                │
│                                            │
│  ┌──── Private Subnet ───┐                │
│  │  - ECS Tasks          │                │
│  │  - Lambda (in VPC)    │                │
│  └───────────────────────┘                │
│                                            │
│  ┌──── Private Subnet ───┐                │
│  │  - RDS                │                │
│  │  - No internet access │                │
│  └───────────────────────┘                │
└────────────────────────────────────────────┘
```

### 2. Secrets Management

- **AWS Secrets Manager** for API keys, DB credentials
- **IAM roles** (not access keys!) for service-to-service auth
- **Rotated credentials** automatically

### 3. Data Encryption

- At rest: RDS encryption, S3 server-side encryption
- In transit: TLS everywhere (enforced via API Gateway)

## Monitoring & Observability

### CloudWatch Dashboards

Track key metrics:
- API latency (p50, p95, p99)
- Error rates by endpoint
- ECS task CPU/memory
- RDS connections
- Lambda cold starts

### Custom Metrics

```python
cloudwatch = boto3.client('cloudwatch')

def track_llm_cost(model: str, tokens: int):
    cloudwatch.put_metric_data(
        Namespace='AIWorkflows',
        MetricData=[{
            'MetricName': 'LLMTokens',
            'Value': tokens,
            'Unit': 'Count',
            'Dimensions': [{'Name': 'Model', 'Value': model}]
        }]
    )
```

### Alerts

Set up CloudWatch alarms for:
- API error rate > 5%
- P95 latency > 10s
- RDS CPU > 80%
- Daily costs > $20

## Lessons Learned

### 1. Start Simple, Add Complexity When Needed

Resisted urge to over-engineer early. Started with serverless, moved to containers only when we had data showing it was necessary.

### 2. Optimize for Iteration Speed

CDK lets us deploy infrastructure changes in minutes. This velocity is worth more than marginal cost savings.

### 3. Measure Before Optimizing

We wasted a week optimizing cold starts before realizing 95% of requests were warm. Always measure first.

### 4. Don't DIY What AWS Does Well

Considered self-hosting Postgres, Redis, etc. Glad we stuck with managed services - saved countless hours of ops work.

### 5. Budget for Unknowns

Allocated 20% of infrastructure budget for "surprises" (egress costs, API overages, etc.). Used it all.

## What's Next

Current areas of focus:

1. **Multi-region deployment** (disaster recovery)
2. **GPU instances for model fine-tuning** (evaluating EC2 vs. SageMaker)
3. **Real-time usage analytics** (considering ClickHouse or Redshift)

## Final Costs Summary

| Users | Monthly Cost | Cost/User |
|-------|-------------|-----------|
| 0-10 | $30 (EC2) | $3.00 |
| 50 | $150 (Serverless) | $3.00 |
| 300 | $400 (Hybrid) | $1.33 |

The hybrid architecture scaled costs **sub-linearly** while improving performance.

---

*Questions about AWS architecture for AI services? Let's connect on [LinkedIn](https://www.linkedin.com/in/suyi-zhang/)!*
